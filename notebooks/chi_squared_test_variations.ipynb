{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as st\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# tested lib\n",
    "from ab_test.user import User\n",
    "from ab_test.experiment import *\n",
    "from ab_test.hasher_implems import *\n",
    "\n",
    "from tools.chi_squared import ChiSquaredTest as chi\n",
    "from tools.data import DataHelper\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared Test\n",
    "\n",
    "We consider experiments with 2 variations of 50% each.\n",
    "\n",
    "## Definitions\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "* Experiment A has _r = 2_ levels (variation 1 and variation 2)\n",
    "* Experiment B has _c = 2_ levels (variation 1 and variation 2)\n",
    "\n",
    "The null hypothesis states that knowing the variation in experiment A does not help you predict the variation in experiment B.\n",
    "\n",
    "Ho: Variable A and Variable B are independent.\n",
    "\n",
    "Ha: Variable A and Variable B are not independent.\n",
    "\n",
    "### Degrees of Freedom\n",
    "\n",
    "`DF = (r - 1) * (c - 1) = 1`\n",
    "\n",
    "### Expected Frequencies\n",
    "\n",
    "The expected frequency counts are computed separately for each level of one categorical variable at each level of the other categorical variable. Compute r * c expected frequencies, according to the following formula.\n",
    "`Er,c = (nr * nc) / n`\n",
    "\n",
    "where Er,c is the expected frequency count for level r of Variable A and level c of Variable B, nr is the total number of sample observations at level r of Variable A, nc is the total number of sample observations at level c of Variable B, and n is the total sample size.\n",
    "\n",
    "For example, for a sample of 100 users, in a perfect case, we would have:\n",
    "\n",
    "`Er,c = (50*50) / 100 = 25`\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "The test statistic is a chi-square random variable (Χ2) defined by the following equation.\n",
    "`Χ2 = Σ [ (Or,c - Er,c)2 / Er,c ]`\n",
    "\n",
    "where Or,c is the observed frequency count at level r of Variable A and level c of Variable B, and Er,c is the expected frequency count at level r of Variable A and level c of Variable B.\n",
    "\n",
    "\n",
    "### P-value\n",
    "\n",
    "The P-value is the probability of observing a sample statistic as extreme as the test statistic.\n",
    "\n",
    "### Conclude\n",
    "\n",
    "* If observed chi-square < critical chi-square, then variables are not related.\n",
    "* If observed chi-square > critical chi-square, then variables are not independent (and hence may be related).\n",
    "\n",
    "For DF=1 and a precision of 5% (α=0.05), the critical chi-square is 3.841."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = 1000\n",
    "nb_exp = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /Users/bmoreschini/Projects/venvs/correlations/lib/python3.7/site-packages (0.13.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "def chi_evaluation_over_populations(nb_experiments, log_scale_populations, hashers, nb_jobs):\n",
    "    chi_squre = {hasher_name: list() for hasher_name, hasher in hashers.items()}\n",
    "    for hasher_name, hasher in hashers.items():\n",
    "        for log_population in log_scale_populations:\n",
    "            print('Computing chi square for {hasher_name} hash function on 10^{log_population} users'.format(\n",
    "                hasher_name=hasher_name,\n",
    "                log_population=log_population))\n",
    "            chi_values = Parallel(n_jobs=nb_jobs)(delayed(compute_chi_square)(hasher, 10**log_population) \n",
    "                                                   for _ in range(nb_experiments))\n",
    "            # print(chi_values)\n",
    "            chi_squre[hasher_name].append(sorted(chi_values)[nb_experiments // 2])\n",
    "    return chi_squre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_chi_square(hasher, population):\n",
    "    return chi.statistic_test(DataHelper.generate(hasher, population))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_experiments = 20\n",
    "log_scale_populations = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "hashers = {\n",
    "    \"built-in\": BuiltInHasher(),\n",
    "    \"md5\": Md5Hasher(),\n",
    "    \"sha256\": Sha256Hasher()\n",
    "}\n",
    "nb_jobs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing chi square for built-in hash function on 10^1 users\n",
      "Computing chi square for built-in hash function on 10^2 users\n",
      "Computing chi square for built-in hash function on 10^3 users\n",
      "Computing chi square for built-in hash function on 10^4 users\n",
      "Computing chi square for built-in hash function on 10^5 users\n",
      "Computing chi square for built-in hash function on 10^6 users\n",
      "Computing chi square for md5 hash function on 10^1 users\n",
      "Computing chi square for md5 hash function on 10^2 users\n",
      "Computing chi square for md5 hash function on 10^3 users\n",
      "Computing chi square for md5 hash function on 10^4 users\n",
      "Computing chi square for md5 hash function on 10^5 users\n",
      "Computing chi square for md5 hash function on 10^6 users\n",
      "Computing chi square for sha256 hash function on 10^1 users\n",
      "Computing chi square for sha256 hash function on 10^2 users\n",
      "Computing chi square for sha256 hash function on 10^3 users\n",
      "Computing chi square for sha256 hash function on 10^4 users\n",
      "Computing chi square for sha256 hash function on 10^5 users\n",
      "Computing chi square for sha256 hash function on 10^6 users\n"
     ]
    }
   ],
   "source": [
    "chi_square = chi_evaluation_over_populations(nb_experiments, log_scale_populations, hashers, nb_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'built-in': [1.2698412698412698,\n",
       "  0.37205456800330716,\n",
       "  0.45825227596578405,\n",
       "  0.6001977739844178,\n",
       "  0.5953873988074859,\n",
       "  0.4696830682708968],\n",
       " 'md5': [0.6250000000000001,\n",
       "  0.8914469848740211,\n",
       "  0.7629888771722095,\n",
       "  0.6019726115362953,\n",
       "  0.5103958153466837,\n",
       "  1.3424124898467955],\n",
       " 'sha256': [0.47619047619047616,\n",
       "  0.594574507617987,\n",
       "  1.01657371215682,\n",
       "  0.5999059441499718,\n",
       "  0.6727491297912361,\n",
       "  0.7639091050874401]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = plt.axes()\n",
    "for hasher_name, chi_values in chi_square.items():\n",
    "    ax.plot(log_scale_populations, chi_values, label=hasher_name)\n",
    "\n",
    "plt.legend();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
