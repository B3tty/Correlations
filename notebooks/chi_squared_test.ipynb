{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data analysis and wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import scipy.stats as st\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# tested lib\n",
    "from ab_test.user import User\n",
    "from ab_test.experiment import *\n",
    "from ab_test.hasher_implems import *\n",
    "\n",
    "# tools\n",
    "from tools.chi_squared import ChiSquaredTest as chi\n",
    "from tools.data import DataHelper as data\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi Squared Test\n",
    "\n",
    "We consider experiments with 2 variations of 50% each.\n",
    "\n",
    "## Definitions\n",
    "\n",
    "### Hypothesis\n",
    "\n",
    "* Experiment A has _r = 2_ levels (variation 1 and variation 2)\n",
    "* Experiment B has _c = 2_ levels (variation 1 and variation 2)\n",
    "\n",
    "The null hypothesis states that knowing the variation in experiment A does not help you predict the variation in experiment B.\n",
    "\n",
    "Ho: Variable A and Variable B are independent.\n",
    "\n",
    "Ha: Variable A and Variable B are not independent.\n",
    "\n",
    "### Degrees of Freedom\n",
    "\n",
    "`DF = (r - 1) * (c - 1) = 1`\n",
    "\n",
    "### Expected Frequencies\n",
    "\n",
    "The expected frequency counts are computed separately for each level of one categorical variable at each level of the other categorical variable. Compute r * c expected frequencies, according to the following formula.\n",
    "`Er,c = (nr * nc) / n`\n",
    "\n",
    "where Er,c is the expected frequency count for level r of Variable A and level c of Variable B, nr is the total number of sample observations at level r of Variable A, nc is the total number of sample observations at level c of Variable B, and n is the total sample size.\n",
    "\n",
    "For example, for a sample of 100 users, in a perfect case, we would have:\n",
    "\n",
    "`Er,c = (50*50) / 100 = 25`\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "The test statistic is a chi-square random variable (Χ2) defined by the following equation.\n",
    "`Χ2 = Σ [ (Or,c - Er,c)2 / Er,c ]`\n",
    "\n",
    "where Or,c is the observed frequency count at level r of Variable A and level c of Variable B, and Er,c is the expected frequency count at level r of Variable A and level c of Variable B.\n",
    "\n",
    "\n",
    "### P-value\n",
    "\n",
    "The P-value is the probability of observing a sample statistic as extreme as the test statistic.\n",
    "\n",
    "### Conclude\n",
    "\n",
    "* If observed chi-square < critical chi-square, then variables are not related.\n",
    "* If observed chi-square > critical chi-square, then variables are not independent (and hence may be related).\n",
    "\n",
    "For DF=1 and a precision of 5% (α=0.05), the critical chi-square is 3.841."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = 1000\n",
    "nb_exp = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-In Hash Method\n",
    "\n",
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/         ExpA:Var1 ExpA:Var2 Sum       \n",
      "ExpB:Var1        241       265       506\n",
      "ExpB:Var2        244       250       494\n",
      "Sum              485       515      1000\n"
     ]
    }
   ],
   "source": [
    "# Built-In Hash\n",
    "\n",
    "matrix_bi = data.generate(BuiltInHasher(), population)\n",
    "\n",
    "data.display(matrix_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3114947601598864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.statistic_test(matrix_bi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger scale test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.806703805923462s\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "stat_tests_bi = []\n",
    "\n",
    "for i in range(0, nb_exp):\n",
    "  matrix_bi = data.generate(BuiltInHasher(), population, i)\n",
    "  stat_tests_bi.append(chi.statistic_test(matrix_bi))\n",
    "print(f\"{time.time() - begin}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 0.49848839162172415\n",
      "mean: 1.0976286131174529\n",
      "std deviation: 1.570428571973351\n"
     ]
    }
   ],
   "source": [
    "print(f\"median: {np.median(stat_tests_bi)}\")\n",
    "print(f\"mean: {np.mean(stat_tests_bi)}\")\n",
    "print(f\"std deviation: {np.std(stat_tests_bi)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can accept the null hypothesis (assignations of experiments A and B are independant) if the median above is inferior to the critical value 3.84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MD5\n",
    "\n",
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/         ExpA:Var1 ExpA:Var2 Sum       \n",
      "ExpB:Var1        265       266       531\n",
      "ExpB:Var2        239       230       469\n",
      "Sum              504       496      1000\n"
     ]
    }
   ],
   "source": [
    "matrix_md5 = data.generate(Md5Hasher(), population)\n",
    "data.display(matrix_md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11059820658239633"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.statistic_test(matrix_md5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger scale test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.028624057769775s\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "stat_tests_md5 = []\n",
    "\n",
    "for i in range(0, nb_exp):\n",
    "  matrix_md5 = data.generate(Md5Hasher(), population)\n",
    "  stat_tests_md5.append(chi.statistic_test(matrix_md5))\n",
    "print(f\"{time.time() - begin}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 0.4023301212544441\n",
      "mean: 0.9106694227575067\n",
      "std deviation: 1.280602754906453\n"
     ]
    }
   ],
   "source": [
    "print(f\"median: {np.median(stat_tests_md5)}\")\n",
    "print(f\"mean: {np.mean(stat_tests_md5)}\")\n",
    "print(f\"std deviation: {np.std(stat_tests_md5)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can accept the null hypothesis (assignations of experiments A and B are independant) if the median above is inferior to the critical value 3.84."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sha256\n",
    "\n",
    "### Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/         ExpA:Var1 ExpA:Var2 Sum       \n",
      "ExpB:Var1        256       244       500\n",
      "ExpB:Var2        258       242       500\n",
      "Sum              514       486      1000\n"
     ]
    }
   ],
   "source": [
    "matrix_sha = data.generate(Sha256Hasher(), population)\n",
    "\n",
    "data.display(matrix_sha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Squared Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.016012553842212295"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi.statistic_test(matrix_sha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigger scale test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.556113004684448s\n"
     ]
    }
   ],
   "source": [
    "begin = time.time()\n",
    "stat_tests_sha = []\n",
    "\n",
    "for i in range(0, nb_exp):\n",
    "  matrix_sha = data.generate(Sha256Hasher(), population)\n",
    "  stat_tests_sha.append(chi.statistic_test(matrix_sha))\n",
    "print(f\"{time.time() - begin}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median: 0.4762430969300927\n",
      "mean: 0.9235882968620195\n",
      "std deviation: 1.2267275988020638\n"
     ]
    }
   ],
   "source": [
    "print(f\"median: {np.median(stat_tests_sha)}\")\n",
    "print(f\"mean: {np.mean(stat_tests_sha)}\")\n",
    "print(f\"std deviation: {np.std(stat_tests_sha)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "We can accept the null hypothesis (assignations of experiments A and B are independant) if the median above is inferior to the critical value 3.84."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
